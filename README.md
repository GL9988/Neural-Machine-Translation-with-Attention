# ğŸŒ Neural Machine Translation with Attention  
Custom GRU-based sequence-to-sequence model with attention for Englishâ€“French translation.  

---

## ğŸš€ Motivation  
Built to explore language modeling, attention mechanisms, and sequence learning from scratchâ€”balancing technical rigor with team collaboration.

---

## ğŸ“¦ Dataset  
Sourced from the Tatoeba Project via the "fra.txt" bilingual dataset (18K+ pairs).  
Filtered for clean, short, prefix-based sentence pairs to optimize alignment and fluency.

---

## ğŸ§  Model Architectures  
- **Encoder**: GRU with embedding and dropout  
- **Decoder**: GRU with additive attention and teacher forcing  
- **Tokenization**: Custom vocabulary class with START/END tokens  

---

## ğŸ¯ Sample Output

Tested the trained model on held-out sentences. Results below show high fluency and semantic accuracy:

| ğŸ‡«ğŸ‡· French Input                  | ğŸ‡¬ğŸ‡§ Predicted Translation       | BLEU Score |
|----------------------------------|--------------------------------|------------|
| tu es trÃ¨s intelligent           | you're very intelligent        | 1.00       |
| je suis un tantinet jalouse     | iâ€™m a little bit jealous       | 1.00       |
| elles sont sur le point de partir | theyâ€™re about to leave         | 1.00       |
| nous sommes enneigÃ©s            | weâ€™re snowed in                | 1.00       |
| je ne suis plus inspirÃ©e        | iâ€™m not inspired anymore       | 1.00       |

> âœ… **Average BLEU Score**: `0.96` across 50 test samples  
> âœ… **Crash-free Inference Rate**: `100%` after early stopping

---

## ğŸ§ª Evaluation  
| Method              | BLEU Score | Notes                     |
|---------------------|------------|---------------------------|
| GRU + Attention     | ~0.96      | Consistent across pairs   |
| Visual Output       | âœ…         | Alignment heatmaps shown  |

---

## ğŸ“Š Visualization  
<p align="center">
  <img src="visualizations/attention_heatmap_sample.png" width="480"/>
  <br><em>Attention heatmap: French input vs. English output</em>
</p>

---

## ğŸ§° Tech Stack  
- **Language**: Python  
- **Framework**: PyTorch  
- **Tools**: NumPy, Matplotlib, Seaborn  
- **Evaluation**: BLEU Score, Attention Maps

---

## ğŸ¤ Collaboration  
Led problem scoping, built training loop, and handled model debugging.  
Worked closely with teammates to align logic, resolve tensor mismatches, and integrate modules.

---

## â–¶ï¸ Run This Project  
```bash
git clone https://github.com/yourusername/nmt-gru-attention.git
cd nmt-gru-attention
pip install -r requirements.txt
python train_model.py
